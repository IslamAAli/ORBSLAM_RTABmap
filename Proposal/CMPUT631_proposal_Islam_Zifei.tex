\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{graphicx}              % to include figures
\usepackage{epstopdf}
\usepackage{amsmath}               % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{lipsum,array,amsmath}
\usetikzlibrary{positioning,automata}
\usetikzlibrary{arrows.meta}
\usepackage{pgfplots}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage[tiny]{titlesec}
\usepackage{lastpage}
\usepackage{booktabs}

\pagestyle{fancy}
\fancyhf{}
\rhead{Islam Ali \& Zifei Jiang}
\lhead{CMPUT-631: Project Proposal}
\rfoot{Page \thepage\ of \pageref*{LastPage}}
\lfoot{\scriptsize{}}


\begin{document}


% =================== Header ====================
\begin{center}
{ CMPUT 631: Project Proposal}  \\ 
\Large{\textbf{Performance Enhancement of RTAB-map Utilizing ORB-SLAM2 Depth Information}}  \\
\vspace{.1in}
\begin{table}[H]
\center
\begin{tabular}{clc}
\begin{tabular}[c]{@{}c@{}}Islam Ali\\ iaali@ualberta.ca\end{tabular} & \hspace{3cm} & \begin{tabular}[c]{@{}c@{}}Zifei Jiang\\ zifei.jiang@ualberta.ca\end{tabular}
\end{tabular}
\end{table}
\end{center}
\vspace{5pt}
\hrule
\vspace{2pt}
\section*{Abstract}
SLAM (Simultaneous Localization and Mapping) became one of the main building blocks of any modern robotic system due to of the inevitable need for robust and reliable localization and mapping engine in the robotic perception subsystem. A number of trials have been done during the last few decades to provide reliable solutions but each suffered a downside in a certain domain or under certain environmental conditions. Two famous SLAM algorithms (namely RTAB-map and ORB-SLAM2) are considered the industry standard as they provide state-of-the-art performance. However, each suffer critical performance issues in some testing scenarios. In this work, we explore the possibility of enhancing the performance of RTAB-map by utilizing the depth information of ORB-SLAM2. The proposal starts by defining the problem in hand and by giving a quick background and literature review of the efforts exerted in this track. Then, the methodology and procedure are discussed thoroughly to provide a road map of the project activities. Finally, the proposal conclude by providing a mechanism for performance evaluation as well as discussing the significance of this work.
\vspace{5pt}
\hrule
\vspace{10pt}
\section{Problem Definition}
Recently, modern autonomous robotic systems are playing a vital role in a wide spectrum of industrial and non-industrial applications. One problem that is related to such application is robot perception of the environment, as such how it models the environment and how it localize itself in it accurately and reliably. To answer these questions, SLAM was introduces a few decades ago as a method for simultaneous localization and mapping. Two of the major advancements in this field was introduced by the introduction of two state-of-the-art algorithms which are \textit{RTAB-map} \cite{labbe2019rtab} and \textit{ORB-SLAM} with its two versions \cite{mur2015orb}\cite{mur2017orb}.
\section{Background}
\indent \textbf{SLAM (Simultaneous Localization and Mapping)} is the process of generating a model of the environment (a map) and localizing the camera inside it \cite{cadena2016past}. By localization we refer to the estimation of the 6DoF of the moving camera (orientation and position). Many sensors are used in SLAM such as LiDARs, Cameras, and Radars \cite{bresson2017simultaneous}. In this work, we focus on the usage of vision-based SLAM and possibly its integration with Laser-based SLAM.

The conventional pipeline of SLAM consists of two major stages, the first one is responsible for sensor abstraction and processing, which includes features extraction and tracking as well as any long-term data association steps such as bundle adjustment or loop closure \cite{bresson2017simultaneous}\cite{cadena2016past}. The second step is to use the associated data to estimate a map or a model of the environment and, at the same time, estimate the 6DoFs (complete pose) of the camera inside the generated map reliably. 
\section{Literature Review}
\subsection{Visual SLAM}
\indent A wide spectrum of research has been conducted into the SLAM problem with the objective of enhancing its performance, allow for long-term operation, and enable portable and limited resources applications to utilize it in real-time. SLAM algorithms can be categorized to either feature-based method and direct methods \cite{taketomi2017visual}. Feature-based methods depend on extracting features and tracking them through different captured images. The estimation of the camera motion and the map is then determined using either filter-based methods (such as EKF in MonoSLAM) or using bundle adjustment optimization (such as BA used in PTAM). It was shown that BA method can provide better performance due to its ability to use more feature key points when compared to the complex EKF-based solution \cite{strasdat2012visual}. 

On the contrary, direct feature-less methods are usually used on images directly without any abstraction \cite{taketomi2017visual} in order to achieve real-time operation and eliminating the accumulated error usually occurring in the aforementioned feature-based methods. Direct methods differ, mainly, in the density of the map and can be categorized based on that to either dense, semi-dense, or sparse methods \cite{taketomi2017visual}. Methods such as DTAM and LSD-SLAM are examples of the trials done to achieve direct SLAM by means of dense and semi-dense maps while other methods such as SVO and DVO are more advanced steps towards fully direct SLAM algorithms utilizing spare maps \cite{cadena2016past}\cite{taketomi2017visual}.

\subsection{RTAB-Map}
RTAB-Map, (Real-Time Appearance-Based Mapping), is an open source Graph-Based SLAM system. RTAB-Map recently has been used as a platform to comparing various of SLAM algorithms due to its deep integration with ROS \cite{labbe2019rtab}. Based on ROS, developers are able to modify and extend the system easily. In the mean time, RTAB-Map provide two classic visual
odometry algorithms Frame-To-Map(F2M) and Frame-To-Frame(F2F) \cite{Fraundorfer2012}. F2F method registers the new frame against last frame while F2M registers the new frame against a local map features created from past key frames. The mapping process of RTAB-Map is separated from odometry part and to reduce the calculation burden. RTAB-Map create Point Cloud using the depth image directly without any optimization. 

\subsection{ORB-SLAM 1 \& 2}
ORB-SLAM 1 is a monocular SLAM system proposed in 2015 \cite{mur2015orb}. It use ORB features for all nodes in the SLAM system such as tracking, mapping, relocalization and loop closing. ORB features provide high calculation efficiency to enable the real time operation in large environment. Based on ORB-SLAM 1, ORB-SLAM 2 is developed to work with RGBD and stereo camera.  ORB-SLAM 2 has three main parallel threads: tracking, local mapping and loop closing. Since ORB-SLAM 2 optimize both state of the camera and key points in the map, it achieves the state-of-art in accuracy in SLAM systems. 

\subsection{RTAB-Map vs. ORB-SLAM 2}
A number of trials have been made to evaluate the performance of SLAM algorithms (specially RTAB-map and ORB-SLAM 1\&2)  utilizing unified test procedures. 

\section{Research Methodology and Procedure}
\subsection{Baseline Evaluation}
The baseline is the accuracy of RTAB-Map and ORB-SLAM2 on KITTI and TUM datasets. Table \ref{tab:my-table} present some results from multiple papers. The time measurement depends on the computer configurations, thus we will measure the time again on our own configurations. 
\begin{table}[]
    \centering
    \begin{tabular}{@{}ccccccccccccc@{}}
    \toprule
    Odometry  & \multicolumn{10}{c}{KITTI Sequence}                         &     & time(msec)   \\
              & 00  & 01   & 02  & 03  & 04  & 05   & 06  & 07  & 08  & 09  & 10  &     \\ \midrule
    F2F       & 1.4 & 14.5 & 4.7 & 0.4 & 0.2 & 0.72 & 1.8 & 0.6 & 5.8 & 2.2 & 3.0 & 61  \\ \midrule
    F2M       & 1.0 & 4.7  & 4.7 & 0.3 & 0.2 & 0.5  & 0.8 & 0.5 & 3.8 & 2.8 & 0.8 & 82  \\ \midrule
    ORB-RTAB  & 1.0 & 5.3  & 4.4 & 0.2 & 0.2 & 0.5  & 0.6 & 0.5 & 3.0 & 1.5 & 0.9 & 175 \\ \midrule
    ORB-SLAM2 & 1.3 & 10.4 & 5.7 & 0.6 & 0.2 & 0.8  & 0.8 & 0.5 & 3.6 & 3.2 & 1.0 & -   \\ \bottomrule
    \end{tabular}
    \caption{Table 1. Baseline for KITTI Dataset}
    \label{tab:my-table}
    \end{table}

\subsection{Depth Information Generation from ORB-SLAM2}
RTAB-Map team incorporate ORB-SLAM2 by using ORB-SLAM2 as a odometry input, and disabling loop closing and full bundle adjustment of ORB-SLAM2\cite{labbe2019rtab}. Local bundle adjustment of ORB-SLAM2 is still working, which make the modified ORB-SLAM2 similar to F2M. 

Because ORB-SLAM2 optimize the feature points in the map, it can provide us with more accurate depth information for the feature points\cite{mur2017orb}. In our project, we will utilize depth information after optimization, to perform a more accurate odometry estimation.

The RTAB-Map is a Motion-Only Bundle Adjustment, it optimize camera pose by minimizing the reprojection error between matched 3D points in the world coordinate and the observation of camera:
$$
\{\mathbf{R,t}\}= \argmin_{\mathbf{R,t}}\sum_{i\in\mathcal{X}}\rho(||x^i-\pi(\mathbf{RX^i+t})||^2) 
$$ 
In ORB-SLAM2, the system optimize the depth information of feature points in keyframes by utilizing keypoints observation in all frames\cite{mur2017orb}:
$$
\{\mathbf{X^i,R_l,t_l}\}= \argmin_{\mathbf{X^i,R_l,t_l}}\sum_{k\in\mathcal{K}_L\cup\mathcal{K}_F} \sum_{i\in\mathcal{X_k}}\rho(||x^j-\pi(\mathbf{R_kX^j+t_k})||^2) 
$$ 

Comparing to the implementation of Labb{\'e} et. al\cite{labbe2019rtab}, we will utilize optimized keyframe further from ORB-SLAM2, to gain a better accuracy in both trajectory and point cloud map. 

\subsection{System Validation}
In order to have a unified procedure for evaluating the system performance, publicly available datasets with ground truth are utilized to. The datasets were selected so that they can exploit the system boundaries in a wide spectrum of scenarios and conditions. For that purpose, KITTI dataset \cite{Geiger2012CVPR} was selected to cover scenarios in outdoor conditions with random moving objects, and TUM RGB-D dataset \cite{sturm2012benchmark} was selected to cover more static and indoor environment conditions.

\section{Performance Evaluation}
The three corner stones of performance in computer science are accuracy, efficiency, and storage requirements. In this work, we focus on addressing \textit{accuracy} aspects of the system which are defined by the relation between the generated trajectory and ground truth data. 

The \textit{Absolute Trajectory Error (ATE)} was defined in \cite{8710464} as a performance metric to stand on the accuracy of a SLAM system vs. a ground truth. The ATE is defined by:
\begin{equation}
ATE(t_i) = \Vert (x_{t_i}^*,y_{t_i}^*) - (x_{t_i},y_{t_i}) \Vert
\end{equation}
where $(x_{t_i}^*,y_{t_i}^*)$ are the ground truth coordinates at $t_i$ , and $(x_{t_i},y_{t_i})$ are the coordinates generated by the SLAM algorithm under test at the same epoch. For a more detailed representation of this performance metric, statistical functions are applied to this metric such as Root Mean Square (RMS), mean, median, variance, and standard deviation. Additionally, the maximum and minimum $ATE$ are reported to define the system limits while operating. 
\section{Significance of Proposed Research}
As discussed in previous sections, both RTAB-map and ORB-SLAM2 are state-of-the-art algorithms and are able to provide accurate localization and mapping information under a number of conditions. Integration of both algorithms can extend the boundaries of each and can yield a more robust and stable SLAM system with the ability to work in even more challenging conditions. Such improvement can contribute in the all time quest of having an out-of-the-box SLAM system \cite{cadena2016past} that can be accurate and optimized for long-term operation.

\newpage
\bibliographystyle{ieeetr}
\bibliography{journal09}
 
\end{document}