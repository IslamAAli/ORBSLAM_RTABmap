\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{graphicx}              % to include figures
\usepackage{epstopdf}
\usepackage{amsmath}               % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{lipsum,array,amsmath}
\usetikzlibrary{positioning,automata}
\usetikzlibrary{arrows.meta}
\usepackage{pgfplots}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage[tiny]{titlesec}
\usepackage{lastpage}


\pagestyle{fancy}
\fancyhf{}
\rhead{Islam Ali \& Zifei Jiang}
\lhead{CMPUT-631: Project Proposal}
\rfoot{Page \thepage\ of \pageref*{LastPage}}
\lfoot{\scriptsize{}}


\begin{document}


% =================== Header ====================
\begin{center}
{ CMPUT 631: Project Proposal}  \\ 
\Large{\textbf{Performance Enhancement of RTAB-map Utilizing ORB-SLAM2 Depth Information}}  \\
\vspace{.1in}
\begin{table}[H]
\center
\begin{tabular}{clc}
\begin{tabular}[c]{@{}c@{}}Islam Ali\\ iaali@ualberta.ca\end{tabular} & \hspace{3cm} & \begin{tabular}[c]{@{}c@{}}Zifei Jiang\\ zifei.jiang@ualberta.ca\end{tabular}
\end{tabular}
\end{table}
\end{center}
\vspace{5pt}
\hrule
\vspace{2pt}
\section*{Abstract}
SLAM (Simultaneous Localization and Mapping) became one of the main building blocks of any modern robotic system due to of the inevitable need for robust and reliable localization and mapping engine in the robotic perception subsystem. A number of trials have been done during the last few decades to provide reliable solutions but each suffered a downside in a certain domain or under certain environmental conditions. Two famous SLAM algorithms (namely RTAB-map and ORB-SLAM2) are considered the industry standard as they provide state-of-the-art performance. However, each suffer critical performance issues in some testing scenarios. In this work, we explore the possibility of enhancing the performance of RTAB-map by utilizing the depth information of ORB-SLAM2. The proposal starts by defining the problem in hand and by giving a quick background and literature review of the efforts exerted in this track. Then, the methodology and procedure are discussed thoroughly to provide a road map of the project activities. Finally, the proposal conclude by providing a mechanism for performance evaluation as well as discussing the significance of this work.
\vspace{5pt}
\hrule
\vspace{10pt}
\section{Problem Definition}
Recently, modern autonomous robotic systems are playing a vital role in a wide spectrum of industrial and non-industrial applications. One problem that is related to such application is robot perception of the environment, as such how it models the environment and how it localize itself in it accurately and reliably. To answer these questions, SLAM was introduces a few decades ago as a method for simultaneous localization and mapping. Two of the major advancements in this field was introduced by the introduction of two state-of-the-art algorithms which are \textit{RTAB-map} \cite{labbe2019rtab} and \textit{ORB-SLAM} with its two versions \cite{mur2015orb}\cite{mur2017orb}.
\section{Background}
\indent \textbf{SLAM (Simultaneous Localization and Mapping)} is the process of generating a model of the environment (a map) and localizing the camera inside it \cite{cadena2016past}. By localization we refer to the estimation of the 6DoF of the moving camera (orientation and position). Many sensors are used in SLAM such as LiDARs, Cameras, and Radars \cite{bresson2017simultaneous}. In this work, we focus on the usage of vision-based SLAM and possibly its integration with Laser-based SLAM.

The conventional pipeline of SLAM consists of two major stages, the first one is responsible for sensor abstraction and processing, which includes features extraction and tracking as well as any long-term data association steps such as bundle adjustment or loop closure \cite{bresson2017simultaneous}\cite{cadena2016past}. The second step is to use the associated data to estimate a map or a model of the environment and, at the same time, estimate the 6DoFs (complete pose) of the camera inside the generated map reliably. 
\section{Literature Review}
\subsection{Visual SLAM}
\indent A wide spectrum of research has been conducted into the SLAM problem with the objective of enhancing its performance, allow for long-term operation, and enable portable and limited resources applications to utilize it in real-time. SLAM algorithms can be categorized to either feature-based method and direct methods \cite{taketomi2017visual}. Feature-based methods depend on extracting features and tracking them through different captured images. The estimation of the camera motion and the map is then determined using either filter-based methods (such as EKF in MonoSLAM) or using bundle adjustment optimization (such as BA used in PTAM). It was shown that BA method can provide better performance due to its ability to use more feature key points when compared to the complex EKF-based solution \cite{strasdat2012visual}. 

On the contrary, direct feature-less methods are usually used on images directly without any abstraction \cite{taketomi2017visual} in order to achieve real-time operation and eliminating the accumulated error usually occurring in the aforementioned feature-based methods. Direct methods differ, mainly, in the density of the map and can be categorized based on that to either dense, semi-dense, or sparse methods \cite{taketomi2017visual}. Methods such as DTAM and LSD-SLAM are examples of the trials done to achieve direct SLAM by means of dense and semi-dense maps while other methods such as SVO and DVO are more advanced steps towards fully direct SLAM algorithms utilizing spare maps \cite{cadena2016past}\cite{taketomi2017visual}.

\subsection{RTAB-Map}
\subsection{ORB-SLAM 1 \& 2}
\subsection{RTAB-Map vs. ORB-SLAM 2}
A number of trials have been made to evaluate the performance of SLAM algorithms (specially RTAB-map and ORB-SLAM 1\&2)  utilizing unified test procedures.
\section{Research Methodology and Procedure}
\subsection{Baseline Evaluation}
\subsection{Depth Information Generation from ORB-SLAM2}
\subsection{Data Synchronization}
\subsection{System Validation}
In order to have a unified procedure for evaluating the system performance, publicly available datasets with ground truth are utilized to. The datasets were selected so that they can exploit the system boundaries in a wide spectrum of scenarios and conditions. For that purpose, KITTI dataset \cite{Geiger2012CVPR} was selected to cover scenarios in outdoor conditions with random moving objects, and TUM RGB-D dataset \cite{sturm2012benchmark} was selected to cover more static and indoor environment conditions.

\section{Performance Evaluation}
The three corner stones of performance in computer science are accuracy, efficiency, and storage requirements. In this work, we focus on addressing \textit{accuracy} aspects of the system which are defined by the relation between the generated trajectory and ground truth data. 

The \textit{Absolute Trajectory Error (ATE)} was defined in \cite{8710464} as a performance metric to stand on the accuracy of a SLAM system vs. a ground truth. The ATE is defined by:
\begin{equation}
ATE(t_i) = \Vert (x_{t_i}^*,y_{t_i}^*) - (x_{t_i},y_{t_i}) \Vert
\end{equation}
where $(x_{t_i}^*,y_{t_i}^*)$ are the ground truth coordinates at $t_i$ , and $(x_{t_i},y_{t_i})$ are the coordinates generated by the SLAM algorithm under test at the same epoch. For a more detailed representation of this performance metric, statistical functions are applied to this metric such as Root Mean Square (RMS), mean, median, variance, and standard deviation. Additionally, the maximum and minimum $ATE$ are reported to define the system limits while operating. 
\section{Significance of Proposed Research}
As discussed in previous sections, both RTAB-map and ORB-SLAM2 are state-of-the-art algorithms and are able to provide accurate localization and mapping information under a number of conditions. Integration of both algorithms can extend the boundaries of each and can yield a more robust and stable SLAM system with the ability to work in even more challenging conditions. Such improvement can contribute in the all time quest of having an out-of-the-box SLAM system \cite{cadena2016past} that can be accurate and optimized for long-term operation.

\newpage
\bibliographystyle{ieeetr}
\bibliography{journal09}
 
\end{document}